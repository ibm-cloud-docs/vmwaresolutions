---

copyright:

  years:  2019, 2022

lastupdated: "2022-04-28"

subcollection: vmwaresolutions


---

{{site.data.keyword.attribute-definition-list}}

# Troubleshooting Red Hat OpenShift problems
{: #openshift-runbook-runbook-trbl-intro}

Use the troubleshooting information to diagnose and fix problems with {{site.data.keyword.redhat_openshift_full}}.

## RHEL subscription
{: #openshift-runbook-runbook-trbl-intro-sub}

If you encounter a problem with your subscription, use the following command to run a query.

```bash
subscription-manager list --available --all
```

## Load-balancer
{: #openshift-runbook-runbook-trbl-intro-lb}

To check that load balancing is working, use the following command from the bastion node. Load balancing is successful if the result is a full set of headers.

```bash
wget --no-check-certificate https://api.ocp.dallas.ibm.local:6443
```

## Red Hat CoreOS
{: #openshift-runbook-runbook-trbl-intro-coreos}

You do not need to connect by using SSH to node, but if you need to, you can do so through the bastion node. The following example connects to the bootstrap server by using the following command:

```bash
ssh core@192.168.133.9
```

If you get an error, then try the following commands that disable the checking of the fingerprint:

```bash
ssh -o StrictHostKeyChecking=no core@192.168.133.9
```

This example shows how to connect to control-plane node from the bastion node to view the logs and change the permission to make them readable. The directory name might be different.

```bash
ssh -i /root/.ssh/id_rsa core@192.168.133.12
sudo su
chmod 777 /var/log/pods/b2810e842791d83d48a4684295b7cd01/etcd-member/0.log
```

This example shows how to download the log to the bastion node and then on to the jump-server or remote device for readability and the ability to parse the logs. The directory name might be different.

```bash
scp -i /root/.ssh/id_rsa core@192.168.133.10:/var/log/pods/b2810e842791d83d48a4684295b7cd01/etcd-member/0.log 0.log
```

## Red Hat OpenShift
{: #openshift-runbook-runbook-trbl-intro-openshift}

Gets a list of nodes and their status:

```bash
oc get nodes
```

When you use kubectl, a preference takes effect while it determines which kubeconfig file is used.

* use the `--kubeconfig` flag, if specified.
* use the KUBECONFIG environment variable, if specified.
* use the `$HOME/.kube/config` file.

To export the kubeconfig that is created by the {{site.data.keyword.redhat_openshift_notm}} Installer to an environment variable, use the following command:

```bash
export KUBECONFIG=/opt/ocpinstall/auth/kubeconfig
```

## Deleting deployment
{: #openshift-runbook-runbook-trbl-intro-del}

If you encounter a problem with your Terraform deployment, you can delete your deployment with the following command.

```bash
terraform destroy
```

In some cases, you might have issues with Terraform to finish the automation. In these cases, you might need to delete your deployment manually by using vCenter and by deleting the Terraform state files.

1. Remove the `ocp` folder and its contents in vCenter.
2. Remove the `ocp` resource group.
3. Remove the `rm /opt/ocpinstall/installer/upi/vsphere/terraform.tfstate` Terraform state file.

After these steps, you can fix your deployment issue and redeploy the {{site.data.keyword.redhat_openshift_notm}} platform.

## Generating new ignition files
{: #openshift-runbook-runbook-trbl-intro-newign}

Your ignition files are valid for 24 hours. You can generate the `.ign` files by completing the following steps:

1. Remove old state, configuration, and `ign` files:
    ```bash
    cd /opt/ocpinstall
    rm -R .openshift_install.log .openshift_install_state.json auth *.ign metadata.json
    ```

2. Copy {{site.data.keyword.redhat_openshift_notm}} the `install-config` backup to yaml:
    ```bash
    cp install-config.bak install-config.yaml
    openshift-install create ignition-configs --dir=/opt/ocpinstall/
    ```

3. Copy bootstrap.ign to nginx home folder.
    ```bash
    cp bootstrap.ign /usr/share/nginx/html
    ```

4. Replace the primary section (cat master.ign) and the worker section (cat worker.ign) in terraform.tfvars.
    nano /opt/ocpinstall/installer/upi/vsphere/terraform.tfvars.

    ```bash
    // Ignition config for the control plane machines. You should copy the contents of the master.ign generated by$
    control_plane_ignition = <<END_OF_MASTER_IGNITION
    <replace with new master.ign>
    END_OF_MASTER_IGNITION

    // Ignition config for the compute machines. You should copy the contents of the worker.ign generated by the i$
    compute_ignition = <<END_OF_WORKER_IGNITION
    <replace with new worker.ign>
    END_OF_WORKER_IGNITION
    ```

## Taking a snapshot of Red Hat OpenShift
{: #openshift-runbook-runbook-trbl-snapshot}

You might want to stop and resume {{site.data.keyword.redhat_openshift_notm}} Cluster VMs during development or testing. You must consider the following before you take a snapshot.

During the installation of {{site.data.keyword.redhat_openshift_notm}} 4.x clusters, a bootstrap certificate is created that is used on the control-plane nodes to create certificate signing requests (CSRs) for kubelet client certificates (one for each node or kubelet). This certificate is used to identify each kubelet on any node. Because these certificates cannot be revoked, they are made with a short expiration time of 24 hours after cluster installation. All nodes other than the control-plane nodes have a service account token that is revocable. The bootstrap certificate is valid only for 24 hours after cluster installation. After the initial 24 hours, the certificate expires every 30 days.

The first control-plane kubelet lasts for 24 hours before it is re-created. If you are taking a snapshot immediately after deployment, the control-plane kubelet does not yet have a 30-day client certificate. Then, the missing kubelet client certificate refresh window renders the cluster unusable, because the bootstrap credential cannot be used when the cluster is back up. Practically, this process requires an {{site.data.keyword.redhat_openshift_notm}} 4 cluster to be running for at least 25 hours after installation before it can be shut down.

You can check the validity of the certificate by running the following command in the bastion host after deployment:

```bash
ssh -i ~/.ssh/id_rsa -o StrictHostKeyChecking=no core@192.168.133.10 -- sudo openssl x509 -text -noout -in /var/lib/kubelet/pki/kubelet-client-current.pem
```

Run the following command to check the lifetime of the certificate of the output.

```bash
Warning: Identity file id_rsa_crc not accessible: No such file or directory.
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            6a:73:78:19:f3:1e:8f:0c:a9:51:b8:53:f4:eb:29:8d:49:fa:7e:fd
        Signature Algorithm: sha256WithRSAEncryption
        Issuer: CN = kube-csr-signer_@1573016574
        Validity
            Not Before: Nov  6 08:22:00 2019 GMT
            Not After : Dec  6 04:57:43 2019 GMT
```

For more information about shutting down the cluster after installation, see [Enabling {{site.data.keyword.redhat_openshift_notm}} 4 Clusters to Stop and Resume Cluster VMs](https://blog.openshift.com/enabling-openshift-4-clusters-to-stop-and-resume-cluster-vms/){: external}.

After the initial 24 hours certificate renewal, cluster snapshot is enabled to resume at any time in the next 30 days. After the 30 days, the certificate validity will make the cluster snapshot unusable.

## Related links
{: #vcs-openshift-runbook-trbl-related}

* [Install on vSphere: User-Provisioned Infrastructure](https://cloud.redhat.com/openshift/install/vsphere/user-provisioned){: external}
* [Install a cluster on vSphere](https://docs.openshift.com/container-platform/4.7/installing/installing_vsphere/installing-vsphere.html){: external}
* [Index of public {{site.data.keyword.redhat_openshift_notm}} v4 clients](https://mirror.openshift.com/pub/openshift-v4/clients/ocp/latest/?extIdCarryOver=true&sc_cid=701f2000001Css5AAC){: external}
* [Understanding persistent storage](https://docs.openshift.com/container-platform/4.7/storage/understanding-persistent-storage.html#understanding-persistent-storage){: external}
* [ssh-keygen - Generate a New SSH Key](https://www.ssh.com/ssh/keygen/){: external}
* [Configure PowerCLI and PowerNSX on macOS](https://readysetvirtual.wordpress.com/2018/04/06/configure-powercli-and-powernsx-on-macos/){: external}
* [Visual Studio Code](https://code.visualstudio.com/){: external}
* [Terraform Getting Started](https://learn.hashicorp.com/terraform#getting-started){: external}
* [Windows 2016 PowerShell DNS](https://docs.microsoft.com/en-us/powershell/module/dnsserver/?view=win10-ps){: external}
* [PowerCLI core documentation](https://powercli-core.readthedocs.io/en/latest/index.html){: external}
