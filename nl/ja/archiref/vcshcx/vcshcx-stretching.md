---

copyright:

  years:  2016, 2019

lastupdated: "2019-02-16"

---

# ネットワーク・ストレッチと仮想マシンのマイグレーション
{: #vcshcx-stretching}

## ネットワーク・ストレッチ
{: #vcshcx-network-stretching}

### ネットワーク・ストレッチの概念とベスト・プラクティス
{: #vcshcx-stretching-best-practices-network}

クライアント・サイドのネットワークをクラウド・サイドの VXLAN に橋渡しするためのかぎとなるのは、独自の HCX テクノロジーで構成される高度なマルチトンネル VPN です。これは NSX を基礎とするものではありませんが、NSX と連携し、その機能を拡張します。このプロセスは、クライアント・サイドの vCenter Web ユーザー・インターフェース (UI) によって制御され、デプロイメントが自動化され、クライアントとクラウドの両サイドのエンドポイントが確立されます。ストレッチ対象のネットワークの選択は、個別または一括で行います。

さらに、ネットワーク・ストレッチ・ワークフローの一環として、クラウド・サイドの NSX が VXLAN を構築します。次いで VXLAN は、クラウド・サイドの指定された L3 デバイス (未接続状態のままの DLR または ESG) およびクラウド・サイドの L2C アプライアンスで作成されたインターフェースに接続します。

特定のアプリケーションをマイグレーションする場合、通常、対象となる仮想マシン (VM) が使用中のすべてのネットワークを、{{site.data.keyword.cloud}} インスタンスにストレッチする必要があります。

上の文で「常に」ではなく「通常」と書かれているのはなぜでしょうか? VM のマイグレーション後に特定のトラフィックをクライアント・サイドから切断すると役立つことがあります。例えば、VM ゲスト・バックアップ・クライアントの場合、クラウドに移動するときに高帯域幅を使用することがあります。この VM がマイグレーションされるときにゲスト内バックアップ・クライアントは不要です。クラウド・サイドの最新のブロック・レベル・バックアップによって自動抽出されるためです。

バックアップ・ネットワークが使用されている場合、各 VM にアクセスしてゲスト内クライアント・バックアップのスケジュールをシャットオフする代わりに、クライアントのバックアップ・ネットワーク・アダプターを接続しない、という手法を採用すると、バックアップが失敗します。これは、すべての VM がマイグレーション後の処理に到達してゲスト内バックアップ・クライアントを無効化できるようになるまでの一時的な状態です。

1 本の L2C の帯域幅は理論上 4 Gbps ですが、これは 1 組の L2C ペア内に設定されたすべてのストレッチ・ネットワークを合わせた限度となるため、単一のストレッチ・ネットワークではその数値に到達不可能です。アンダーレーの帯域幅が十分に割り振られていて、待ち時間が短い (およそ 10 ミリ秒以下) 場合には、単一のストレッチ・ネットワークで約 1 Gbps を実現可能です。

### ネットワークをストレッチするためのプロセス
{: #vcshcx-stretching-process-stretch}

HCX を利用してネットワーク (VLAN または VXLAN) をストレッチするには、クライアント・サイドの vCenter Web UI から以下のステップを実行します。

1. 選択したそれぞれのポート・グループに関して、vCenter Web UI の**「Networks」**タブに移動し、ストレッチするネットワークを右クリックします。その後、**「Hybridity Actions」->「Extend Networks to the Cloud」**と選択します。
2. 接続先のクラウド・サイドの L3 デバイスと、使用される L2C アプライアンスを選択します。現在のデフォルトのゲートウェイとサブネット・マスクを CIDR 形式で入力します。
3. 画面下部にある**「Stretch」**をクリックし、ネットワーク・ストレッチ・ワークフローを開始します。

ネットワークの進行状況のモニターは、vCenter Client の「Tasks」ペインで行います。

### 隣接ルーティング・オプション
{: #vcshcx-stretching-prox-routing}

どのタイプの経路最適化機能も使用されていない場合、あらゆる L3 アクセスにおいて拡張ネットワークはクライアント・サイドに戻るようにルーティングされます。このトロンボーン現象により、非効率的なトラフィック・パターンが生じます。パケットがクライアント (ソース) とクラウド間で行ったり来たりする必要があるからです (ソースと宛先の両方の VM がクラウド内に存在する場合であっても同様です)。HCX の隣接ルーティング・フィーチャーは、この問題に対処してトラフィックのローカル出口を設けるように設計されています。

## vMotion
{: #vcshcx-stretching-vmotion}

HCX の vMotion 機能は vSphere vMotion 機能を拡張し、それぞれ別個の SSO ドメインにあるさまざまなバージョンの vSphere を、さまざまなタイプのネットワーク接続を使ってインターネット経由で実行できるようにします。HCX では、接続に使用されるネットワークがセキュアではないという前提で機能するので、接続の種類に関係なく、トラフィックの移動は必ず暗号化されたトンネルを介して行われます。

### vMotion の概念とベスト・プラクティス
{: #vcshcx-stretching-best-practices-vmotion}

HCX は、両方向で使用できる vMotion プロキシーであると見なすことができます。HCX の各インスタンスは vSphere データ・センター内の単一の ESXi ホストをエミュレートします。このホストはすべてのクラスターの外部にあり、クラウド・ゲートウェイ・フリート・コンポーネント (CGW) の「フロント」となります。プロキシー・ホストは、現在の表示サイトにリンクされている HCX サイトごとに設定されます。vMotion がリモート・ホストに対して開始されると、ローカル ESXi ホストは、CGW のフロントとなるローカル・プロキシー ESXi ホストへ対象 VM を vMotion で移動します。この CGW は、リモート・サイドの CGW との間の暗号化されたトンネルの保守も行います。

これと同時に、リモートの ESXi プロキシー・ホストから宛先の vSphere 物理 ESXi ホストに対して vMotion が開始され、宛先側ではトンネルを介してソースの CGW のデータを受信します。vMotion が採用される場合、一括マイグレーション・オプションとは異なり、一度に実行されるのは 1 つの VM マイグレーション操作のみです。そのため、大量の VM をマイグレーションする場合には、ダウン時間を許容できない場合や VM をリブートするとリスクが生じたりする場合にのみ、vMotion を使用することをお勧めします。ただし、標準の vMotion の場合と同様、VM はプロセス中も稼働できます。

これまでの計測結果として、単一の vMotion では、LAN 上で最高約 1.7 Gbps、WAN オプティマイザーを使用する WAN で 300 から 400 Mbps の速度が計測されています。LAN 上の 1.7 Gbps と WAN 上の 400 Mbps は等価ではありませんが、観察対象の環境で計測されたどちらも最大値です。観察対象の環境の構成は、10 GB LAN vMotion ネットワークおよび 1GB インターネット・アップリンクで、実動 Web トラフィックを共有します。

vMotion は以下の場合に使用します。
- VM のシャットダウンや始動に手間がかかるか、アップタイムに時間がかかる場合があってシャットダウンにリスクが生じる可能性がある場合。
- Oracle Rac クラスターなど、ディスク UUID が必要となるクラスター・タイプのアプリケーション。vMotion は、宛先でディスク UUID を変更しません。
- 単一の VM をできるだけ短時間で移動する場合。
- スケジュールされたマイグレーションが不要である場合。

### 操作
{: #vcshcx-stretching-operation}

HCX Web UI スナップイン・ポータルまたは vSphere Web Client コンテキスト拡張メニューを使用して、クロスクラウド vMotion を開始できます。どちらの場合も、同じマイグレーション・ウィザードが表示されます。コンテキスト・メニューの場合、マイグレーション操作用に 1 つの VM のみを選択できます。ポータルの場合には、複数の VM を選択できます。

VM の逆方向のマイグレーションを行えるのは Web UI ポータルからのみです。その場合、HCX マイグレーション・ウィザードで**「Reverse migration」**チェック・ボックスを使用します。

## 一括マイグレーション
{: #vcshcx-stretching-bulk-mig}

### 一括マイグレーションの概念とベスト・プラクティス
{: #vcshcx-stretching-best-practices-bulk-mig}

HCX の一括マイグレーション機能では vSphere レプリケーションを使用して、宛先の vSphere HCX インスタンスで VM を再作成するときにディスク・データをマイグレーションします。VM のマイグレーションにより、以下のワークフローが生じます。
- 宛先サイドで新しい VM とその対応する仮想ディスクの作成。
- 新しい VM への VM データのレプリケーション。レプリケーションは、切り替えスケジュールに関係なくウィザードが完了するとすぐに開始します。
- 元の VM のパワーダウン。
- パワーオフ期間中に発生する、変更データの最終レプリケーション。
- 宛先サイドにおける新しい VM のパワーオン。
- クラウド・フォルダーに移動された元の VM の名前変更と移動。

vMotion と比較して一括マイグレーションには以下の利点があります。
- 同時に多数の VM をマイグレーションできる。
- より一貫性のある方法で帯域幅を使用できる。vMotion の場合、使用する帯域幅に変動が生じ、ネットワーク・モニタリング・ツールや WAN オプティマイザー UI で上下動が観測される可能性があります。
- 単一の vMotion の場合と比較して、一括マイグレーションを使用する場合にはネットワーク帯域幅の全体的使用量が高くなる。
- 一括マイグレーションをスケジュールすることにより、スケジュールされた停止期間中に新しくマイグレーションされた VM に切り替えることができます。
- クラウド・サイドではない、仮想 CPU フィーチャーを現在使用している VM をマイグレーションできる (vMotion の場合には失敗します)。

vMotion と比較して一括マイグレーションには以下の欠点があります。
- vMotion に比べ、個々の VM マイグレーション速度がかなり遅い。
- 宛先サイドに新たに VM が複製されるたびに VM で短時間のダウン時間が生じる。
- ディスクの順序とディスク UUID に依存する VM (Oracle RAC) の場合、UUID が変更されて問題が生じ、元とは異なるディスクが表示される可能性がある。それに伴い、仮想ディスク・デバイスへの OS パスが変更されることがあります。

## マイグレーション・タイプに関するベスト・プラクティス
{: #vcshcx-stretching-mig-type-best-practices}

### 共有ディスク・クラスター
{: #vcshcx-stretching-shared-disk-clusters}

Oracle RAC、MS Exchange、MS-SQL などのアプリケーションのクラスターでは、複数の VM が 1 つのクラスターに参加し、すべての VM またはクラスター・ノードが使用する共有ディスクを必要とします。アプリケーション・クラスターの一部であるディスク (非 OS 仮想ディスク) に対して、すべての VM ノードで VMware マルチライター・フラグを有効にする必要があります。あらゆる仮想ディスクに対してマルチライター・フラグが有効になっている VM はサポートされていません。

マルチライター仮想ディスクが有効なクラスターのマイグレーション:
- vMotion を使用します。元の VM ディスクと UUID マッピングが維持されるためです。
- クラスターはマイグレーション中に低下状態 (単一ノード) で稼働状態を維持します。
- クラスターでは、マイグレーションの開始前とマイグレーションの完了後にダウン時間が生じ、クラスター VM ノードでマルチライター構成を再アセンブルします。

マルチライター・ディスクが有効なクラスターをマイグレーションするには、以下のステップを実行します。
1. アプリケーションのベスト・プラクティスに基づいて、クラスターとすべてのノードを停止します。
2. アプリケーションで必要となる場合には、マルチライター構成が設定されている仮想ディスクの各ノード VM におけるディスクの順序をメモに取ります。
3. 仮想ディスク UUID フィーチャーを使用する Oracle などのアプリケーションの場合、特定の ESXi ホストにログインし、`vmkfstools -J getuuid /vmfs/volumes/datastore/VM/vm.vmdk` コマンドを実行して、
クラスターに設定されているマルチライター・フラグを必要とする仮想ディスク・ファイルごとに UUID を取得します。
  これは、ベスト・プラクティスによって、オペレーティング・システムにおけるパスの表示方法に基づいてディスクの順序を調整する場合に必要となります。vMotion によってディスク (disk1、disk2、disk3) が再配列される可能性はありますが、UUID は同じままです。
  メモした UUID のディスク・マッピング情報を使用して、ディスク命名順序を再作成します。必要に応じて、マイグレーション完了時に Scsi ID も確認します。いずれかの方法でアプリケーションが機能するようにします。この方法は、Oracle インスタンスに、アプリケーションのトラブルシューティング用にマップされる仮想ディスクが多数存在する場合に使用されます。
4. プライマリーと見なされているもの以外の仮想ディスクをすべてのクラスター VM ノードから削除します。
5. クラスター・ディスクを現在所有している唯一のプライマリー VM クラスター・ノードからマルチライター・フラグを削除します。
6. ダウン時間を最小にするために必要な場合はプライマリー・クラスター・ノードを再度稼働状態にします。
7. vMotion ですべてのクラスター・ノードをマイグレーションします。最初にプライマリー・クラスターをマイグレーションし、パワーオフしたときに他のすべてのノードをマイグレーションします。
8. プライマリー・ディスクが所有しているノードのマイグレーションが完了したら、それをパワーダウンします。
9. 必要に応じて、適切なディスク UUID と scsi ID でディスクの順序を再マップします。アプリケーションが機能するために再マップが必須であるわけではありません。
10. プライマリー・ノードでマルチライター・フラグを再び有効にします。
11. プライマリー・ノードを開始し、操作を検証します。
12. 他のすべてのクラスター・ノード VM でディスクをマップするかマルチライター・フラグを有効化し、それらをパワーオンします。
13. 他のクラスター・ノードの操作を検証します。

### 一般の VM
{: #vcshcx-stretching-general-vms}

HCX の機能が正しく動作していることを確認した後に、一括マイグレーションを導入する必要があります。冗長アプリケーションが関係している場合には、一括マイグレーションが必要です。VM 数が数百、数千と多数あるような Web サーバーをマイグレーションする場合などもこれに該当します。

### 直接接続された NAS を使用する VM
{: #vcshcx-stretching-vms-direct-nas}

通常 NFS は、Web サーバー・コンテンツなどのデータを多くのサーバーで共有するときに使用されます。iSCSI は E メールや RDBMS などのアプリケーション・クラスターを構成する VM ノードで導入可能で、通常は NFS に比べて待ち時間の許容度が厳格です。

どちらの場合であっても、{{site.data.keyword.CloudDataCent_notm}} に対する待ち時間を短くできる場合 (iSCSI の場合にはおよそ 7 ms 以下、NFS の場合にはアプリケーションの許容範囲内)、アプリケーションがおよび 1 Gbps 以下の帯域幅で操作を実行できるなら、NAS ネットワークは HCX を使用して {{site.data.keyword.cloud_notm}} の場所にストレッチできます。これを行った後、VM を通常の方法で HCX でマイグレーションすることや vMotion を行うことができます。

マイグレーション後、iSCSI ボリュームを OS と一緒に別のローカル・クラウド・ストレージ・ソリューションにミラーリングすることができます。また、クラウド・ソリューションに属する任意の場所に NFS データを複製できます。考慮する点は以下のとおりです。
- 待ち時間 (iSCSI、または NFS におけるアプリケーション許容範囲)
- 帯域幅 (ストレッチ・ネットワークあたり約 1 Gbps)
- アンダーレー・リンク帯域幅

マイグレーション・ライフサイクルが終わったら、実動環境を試す前に開発アプリケーションまたはステージング・アプリケーションでテストしてください。待ち時間に厳格なストレッチ L2 ネットワークを使用する L2C HCX アプライアンス間のアンダーレー・トンネル・トラフィック (UDP 500 / 4500) に関して QoS を導入できます。

## ネットワーク・スイング
{: #vcshcx-stretching-network-swing}

データ・センターを {{site.data.keyword.cloud_notm}} に移動させることが目標である場合は、HCX を除去する前に行う、最後から 2 番目のステップは、ネットワーク・スイングです。ネットワーク・スイングによって、マイグレーションされた VM を収めるネットワーク・サブネットを、ソースのデータ・センターから {{site.data.keyword.cloud_notm}} の NSX オーバーレイ・ネットワークにマイグレーションできます。

ネットワークのスイングには以下の事柄が関係しています。
- ネットワークからすべてのワークロードが移動されてなくなり、非 VM ネットワーク・デバイスすべてが別のネットワークに移動され、機能的にクラウドにマイグレーションされたか、使用されなくなったことを確認します。
- すべての NSX トポロジーまたは {{site.data.keyword.cloud_notm}} サポート・ネットワーク・トポロジーが完成してネットワーク・スイングをサポートしていることを確認します。例えば、動的ルーティング・プロトコルやファイアウォールなどです。
- UI で HCX ストレッチ解除ネットワーク・ワークフローを実行し、ストレッチ解除されたネットワークのデフォルト・ゲートウェイを引き継ぐ適切なルーティング NSX デバイスを選択します。
- その他のルーティング変更を実行します。例えば、必要に応じて、マイグレーションされたネットワークに変更済みルーティングを挿入したり、ソース・サイトからマイグレーション済みネットワークへのルーティングを除去したり、マイグレーションされていないアプリケーションに関して WAN を介したマイグレーション済みサブネットへのルーティングを確認したりします。
- 可能性のあるすべてのアクセス・ポイント (インターネット、イントラネット、VPN) からのマイグレーション済みアプリケーションのアプリケーション所有者テスト。

すべての VM がクラウドに完全にマイグレーションされた特定のアプリケーションに関するネットワーク・スイングでは考慮事項があります。つまり、プライベート・ネットワーク・サイドで vyatta を使用して MPLS クラウドにルーティングを挿入していて、MPLS でエッジ・ルーティング・デバイスに対するトンネルを設けて {{site.data.keyword.cloud_notm}} IP スペースを回避する場合。
ユーザーには、{{site.data.keyword.cloud_notm}} VRF で設定されたアカウントがあります。一部のアプリケーションはネットワーク・ロード・バランシング仮想 IP (vIP) の背後にあります。こうした vIP は、vyatta の背後の仮想 F5 上のユーザー所有のサブネットにあります。HCX 経由で {{site.data.keyword.cloud_notm}} にスイングされるネットワークに関して MPLS へのより具体的なルーティングをアドバタイズすると他のネットワークでは十分に機能しますが、個々の vIP に関しては /32 ルートが挿入されるために機能しません。

解決策: 通常、WAN プロバイダーは、アドバタイズされた /32 ルートをフィルターにかけて除外します。WAN ベンダーと連携して、これを行えるようにします。

考慮事項と暗黙的に含まれる事柄について以下に示します。
- サブネット、vLAN、VXLAN を共有するアプリケーションは一緒に移動する必要があります。
- ルーティング可能な内部 IP を使用する、ロード・バランサーの背後にあるアプリケーションは、一緒に移動できない場合や、移動したくない場合にはルーティング変更を要求できます。例えば、1 度のスイングで関係するアプリケーションが多すぎて、被るリスクが大きすぎる場合です。
- VMware 管理者、ネットワーク管理者 (顧客、WAN ベンダーを含む)、アプリケーション所有者が関与する必要があります。計画されていない場合であっても、変更は特定のシステムやネットワーク機器に影響を及ぼします。

## 関連リンク
{: #vcshcx-stretching-related}

* [vCenter Server on {{site.data.keyword.cloud_notm}} with Hybridity Bundle の概要](/docs/services/vmwaresolutions/archiref/vcs/vcs-hybridity-intro.html)   
