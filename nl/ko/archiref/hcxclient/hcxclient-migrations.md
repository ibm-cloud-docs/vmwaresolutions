---

copyright:

  years:  2019

lastupdated: "2019-07-09"

subcollection: vmware-solutions


---

# VMware Hybrid Cloud 마이그레이션
{: #hcxclient-migrations}

HCX 서비스 메시 및 네트워크 확장이 프로비저닝되고 확장된 후 다음 단계는 VM을 마이그레이션하는 것입니다.

마이그레이션의 세 가지 유형은 다음과 같습니다.
  -  vMotion
  - 대량 마이그레이션
  - 콜드 마이그레이션

## 조작
{: #hcxclient-migrations-operation}

HCX 웹 UI 스냅인 포털 또는 vSphere 웹 클라이언트 컨텍스트 확장 메뉴를 사용하여 교차 클라우드 vMotion을 시작하십시오. 두 경우 모두 동일한 마이그레이션 마법사가 표시됩니다. 컨텍스트 메뉴의 경우 마이그레이션 조작에 사용하도록 단일 VM만 선택합니다. 포털의 경우 여러 VM을 선택할 수 있습니다.

역마이그레이션 VM은 HCX 마이그레이션 마법사에서 **역마이그레이션** 선택란을 사용하는 웹 UI 포털에서만 가능합니다.

##  vMotion
{: #hcxclient-migrations-vmotion}

HCX의 vMotion 기능은 여러 다른 버전의 vSphere, 개별 SSO 도메인 및 인터넷에서 다양한 유형의 네트워크 연결과 작동하도록 vSphere vMotion 기능을 확장합니다. HCX에서는 연결하는 데 사용하는 네트워크가 안전하지 않다고 간주하므로 연결 유형과 상관없이 항상 암호화된 터널을 통해 트래픽을 이동합니다.

### vMotion의 개념 및 우수 사례
{: #hcxclient-migrations-best-practices-vmotion}

HCX는 본질적으로 vMotion 쌍방향 프록시입니다. HCX의 각 인스턴스에서는 자체적으로 클라우드 게이트웨이 Fleet 컴포넌트(CGW)의 "대행(front)"인 클러스터 외부의 vSphere 데이터 센터에 있는 단일 ESXi 호스트를 에뮬레이트합니다. 프록시 호스트는 현재 표시되는 사이트에 링크된 HCX 사이트마다 표시됩니다. vMotion이 원격 호스트에서 시작되면 로컬 ESXi 호스트가 해당 VM을 로컬 프록시 ESXi 호스트로 마이그레이션합니다. 이 로컬 프록시 ESXi 호스트는 원격 측에서 CGW와 함께 암호화된 터널을 유지보수하는 CGW를 대행합니다.

vMotion 마이그레이션은 터널 전체의 소스 CGW에서 데이터를 받는 한편 원격 ESXi 프록시 호스트에서 대상 vSphere 실제 ESXi 호스트로 시작됩니다. vMotion이 사용되는 경우 대량 마이그레이션 옵션과 달리 한 번에 하나의 VM 마이그레이션 조작만 실행됩니다. 따라서 많은 수의 VM을 마이그레이션하는 경우 중단 시간을 가질 수 없거나 VM을 다시 부팅하는 것이 위험한 경우에만 사용하는 것이 좋습니다. 그러나 표준 vMotion과 같이 VM은 프로세스 중에 라이브일 수 있습니다.

단일 vMotion이 LAN에서는 약 1.7Gbps를 유지하고 WAN에서는 WAN 최적화 프로그램을 통해 300 - 400Mbps를 유지하는 것으로 관찰되었습니다. 그렇다고 해서 LAN의 1.7Gbps가 WWAN 최적화 프로그램을 통한 WAN의 400Mbps와 같다는 의미는 아니며, 이러한 최대값은 특정 환경에서 관찰되었습니다. 이러한 환경은 10GB LAN vMotion 네트워크 및 1GB 인터넷 업링크로 구성되며, 프로덕션 웹 트래픽과 공유됩니다.

다음과 같은 경우 vMotion을 사용하십시오.
- VM을 종료 또는 시작하기가 어렵거나 가동 시간이 길고 VM을 종료하면 위험이 발생하는 경우.
- Oracle RAC 클러스터와 같이 디스크 UUID가 필요한 클러스터 유형 애플리케이션의 경우. vMotion에서 대상의 디스크 UUID를 변경하지 않음에 유의하십시오.
- 단일 VM을 가능한 빨리 이동하려고 합니다.
- 스케줄된 마이그레이션이 필요하지 않습니다.

## 대량 마이그레이션
{: #hcxclient-migrations-bulk-mig}

### 대량 마이그레이션의 개념 및 우수 사례
{: #hcxclient-migrations-best-practices-bulk-mig}

HCX의 대량 마이그레이션 기능에서는 vSphere 복제를 사용하여 디스크 데이터를 마이그레이션하면서 대상 vSphere HCX 인스턴스에서 VM을 다시 작성합니다. VM을 마이그레이션하면 다음 워크플로우가 발생합니다.
- 대상 측과 해당 가상 디스크에 새 VM을 작성합니다.
- VM 데이터를 새 VM으로 복제합니다. 복제는 전환 스케줄링과 상관없이 마법사가 완료되는 즉시 시작합니다.
- 원래 VM의 전원을 끕니다.
- 전원 끄기 기간 동안 데이터 변경사항의 최종 복제가 수행됩니다.
- 대상 측에서 새 VM의 전원을 켭니다.
- 원래 VM의 이름을 바꾸고, 이동된 클라우드 폴더로 이 VM을 이동하십시오.

다음은 vMotion을 통한 대량 마이그레이션의 장점입니다.
- 여러 VM을 동시에 마이그레이션합니다.
- 더 일관된 대역폭을 사용합니다. vMotion에서는 네트워크 모니터링 도구와 WAN Opt UI에서 최대와 최소로 표시되는 대역폭 사용의 변동을 생성할 수 있습니다.
- 대량 마이그레이션을 사용하면 단일 vMotion에서 가능한 것보다 높은 전체 네트워크 대역폭 기능을 사용할 수 있습니다.
- 스케줄된 가동 중단 기간 동안 새로 마이그레이션된 VM으로 전환하도록 대량 마이그레이션을 스케줄링합니다.
- 현재 클라우드 측과는 다른 가상 CPU 기능을 사용하고 있는 VM의 마이그레이션을 허용합니다. 이러한 경우에는 vMotion 마이그레이션에 실패할 수 있습니다.

다음은 vMotion을 통한 대량 마이그레이션의 단점입니다.
- 개별 VM은 vMotion 보다 훨씬 느리게 마이그레이션됩니다.
- 새로운 복제 VVM이 대상 측에 표시되므로 VM이 잠시 가동 중단됩니다.
- 디스크 순서 지정 및 디스크 UUID(Oracle RAC)에 따라 달라지는 VVM에 문제가 있을 수 있고 UUID가 변경됨에 따라 디스크가 다르게 표시될 수 있습니다. 따라서 가상 디스크 디바이스의 OS 경로가 변경될 수 있습니다.

## 마이그레이션 유형 우수 사례
{: #hcxclient-migrations-mig-type-best-practices}

### 공유 디스크 클러스터
{: #hcxclient-migrations-shared-disk-clusters}

Oracle RAC, MS Exchange 및 MS-SQL 클러스터는 모든 VM 또는 클러스터 노드 간에 디스크를 공유해야 하는 클러스터에 두 개 이상의 VM이 참여하는 애플리케이션의 예입니다. 애플리케이션 클러스터의 일부인 디스크(비OS 가상 디스크)용 모든 VM 노드에서 VMware 다중 기록기 플래그를 사용으로 설정해야 합니다. 가상 디스크에 다중 기록기 플래그가 사용된 VM은 지원되지 않습니다.

다중 기록기 가상 디스크가 사용된 클러스터 마이그레이션:
- vMotion을 원래 VM 디스크로 사용하고 UUID 맵핑이 유지보수됩니다.
- 마이그레이션 중에 클러스터는 성능 저하 상태(단일 노드)로 남아 있습니다.
- 클러스터 VM 전체에서 다중 기록기 구성을 리어셈블하기 위해 마이그레이션 전 및 마이그레이션이 완료된 후 클러스터가 작동 중단됩니다.

다중 기록기 디스크를 사용하는 클러스터를 마이그레이션하려면 다음 단계를 완료하십시오.
1. 애플리케이션 우수 사례별로 모든 노드와 클러스터의 전원을 끕니다.
2. 애플리케이션에 필요한 경우 다중 기록기가 구성된 가상 디스크의 각 노드 VM에서 디스크 순서를 기록합니다.
3. Oracle 및 가상 디스크 UUID 기능을 사용하는 기타 모든 애플리케이션의 경우 특정 ESXi 호스트에 로그인한 후 `vmkfstools -J getuuid /vmfs/volumes/datastore/VM/vm.vmdk` 명령을 실행하여 클러스터의 다중 기록기 플래그를 설정해야 하는 각 가상 디스크 파일의 UUID를
가져옵니다.
  우수 사례에서 디스크 순서를 운영 체제에 경로가 표시되는 방법에 맞게 조정하는 경우 필요합니다. vMotion은 디스크(disk1, disk2, disk3)를 다시 정렬할 수 있지만 UUID는 그대로 남아 있습니다.
  마이그레이션이 완료되면 언급된 UUID를 사용하여 디스크 정보를 맵핑하고 디스크 이름 지정 순서를 다시 작성하고, 필요한 경우 SCSI ID를 사용하십시오. 어떤 경우에든 애플리케이션이 작동해야 합니다. Oracle 인스턴스에 애플리케이션의 문제점 해결을 위해 여러 가상 디스크가 맵핑된 경우 사용합니다.
4. 기본으로 간주되는 항목을 제외하고 모든 클러스터 VM에서 가상 디스크를 제거합니다.
5. 현재 유일하게 클러스터 디스크를 소유해야 하는 기본 클러스터 VM에서 다중 기록기 플래그를 제거합니다.
6. 최소 중단 시간에 필요한 경우 기본 클러스터의 전원을 켭니다.
7. vMotion으로 모든 클러스터 노드를 마이그레이션합니다. 먼저 기본 클러스터를 마이그레이션하십시오. 전원이 꺼진 후에 모든 다른 노드를 마이그레이션하십시오.
8. 기본 디스크 소유 노드에서 마이그레이션을 완료하면 전원을 끕니다.
9. 필요한 경우 적절한 디스크 UUID와 SCSI ID를 사용하여 디스크 순서를 다시 맵핑합니다. 애플리케이션이 작동하는 데 재맵핑은 필요하지 않습니다.
10. 기본 노드에서 다중 기록기 플래그를 다시 사용하도록 설정합니다.
11. 기본 노드를 시작하고 조작을 확인합니다.
12. 기타 모든 클러스터 VM에서 다중 기록기 플래그를 사용으로 설정하고 디스크를 맵핑하고 전원을 켭니다.
13. 다른 클러스터 조작을 확인합니다.

### 일반 VM
{: #hcxclient-migrations-general-vms}

HCX의 기능을 중심으로 신뢰도를 빌드하고 나면 대량 마이그레이션을 사용해야 합니다. 중복 애플리케이션의 경우 대량 마이그레이션이 필요합니다. 예를 들어, 웹 서버와 수백 개 또는 수천 개의 VM을 마이그레이션하는 위치가 해당됩니다.

### 직접 접속 NAS를 사용하는 VM
{: #hcxclient-migrations-vms-direct-nas}

NFS는 일반적으로 웹 서버 컨텐츠와 같이 여러 서버에서 데이터를 공유하는 데 사용하기 위해 채택합니다. iSCSI는 이메일이나 RDBMS와 같은 애플리케이션 클러스터로 구성되는 VM 노드 간에 사용할 수 있으며 일반적으로 NFS보다 대기 시간의 영향을 많이 받습니다.

어떤 경우에든 {{site.data.keyword.CloudDataCent_notm}}의 대기 시간이 낮게 유지되고(iSCSI의 경우 < ~7ms 및 애플리케이션에서 NFS에 허용하는 시간) 해당 애플리케이션에서 ~1Gbps 이하의 대역폭으로 작동할 수 있으면 NAS 네트워크가 HCX와 함께 {{site.data.keyword.cloud_notm}} 위치로 확장될 수 있습니다. 이 작업을 완료하고 나면 HCX와 함께 VM을 마이그레이션하거나 VMotion을 수행할 수 있습니다.

마이그레이션 후에 iSCSI 볼륨은 OS와 함께 다른 로컬 클라우드 스토리지 솔루션으로 미러링될 수 있고 NFS 데이터는 클라우드 솔루션의 데이터로 복제될 수 있습니다. 고려해야 하는 사항은 다음과 같습니다.
- 대기 시간(iSCSI 또는 NFS의 애플리케이션 허용 범위)
- 대역폭(확장된 네트워크당 ~1Gbps)
- 언더레이 링크 대역폭

마이그레이션 라이프사이클 후에 프로덕션을 시도하기 전에 개발 또는 스테이징 애플리케이션을 테스트하십시오. QoS는 대기 시간의 영향을 많이 받는 확장 L2 네트워크를 지원하는 L2C HCX 어플라이언스 사이의 언더레이 터널 트래픽(UDP 500/4500)에 사용할 수 있습니다.

## 네트워크 전환(Swing)
{: #hcxclient-migrations-network-swing}

데이터 센터를 모두 {{site.data.keyword.cloud_notm}}로 내보내려는 경우 HCX 제거 전에 마지막에서 두 번째로 수행할 단계는 네트워크 전환(Swing)입니다. 네트워크 전환에서는 소스 데이터 센터에서 {{site.data.keyword.cloud_notm}}의 NSX 오버레이 네트워크로 마이그레이션된 VM을 저장하는 네트워크 서브넷의 마이그레이션을 수행합니다.

네트워크 전환에는 다음 단계가 포함됩니다.
- 네트워크에서 모든 워크로드를 내보내고 비VM 네트워크 디바이스가 다른 네트워크로 이동되었거나 기능적으로 클라우드에 마이그레이션되었거나 더 이상 사용되지 않는지 확인합니다.
- 네트워크 전환을 지원하기 위해 NSX 토폴로지 또는 {{site.data.keyword.cloud_notm}} 지원 네트워크 토폴로지가 완료되었는지 확인합니다. 예를 들어 동적 라우팅 프로토콜과 방화벽이 있습니다.
- UI에서 HCX 확장 해제 네트워크 플로우를 실행하고 확장 해제 네트워크의 기본 게이트웨이를 제어할 적절한 라우팅 NSX 디바이스를 선택합니다.
- 다음과 같은 외부 라우팅 변경을 실행합니다. 마이그레이션된 네트워크의 변경된 라우팅을 삽입하고 마이그레이션된 네트워크에서 소스 사이트로의 라우팅을 제거하고 마이그레이션되지 않은 애플리케이션용으로 WAN 전체에 마이그레이션된 서브넷으로 라우팅하는 작업이 아직 작동하는지 확인합니다.
- 애플리케이션 소유자가 가능한 모든 액세스 지점(인터넷, 인트라넷 및 VPN)에서 마이그레이션 애플리케이션을 테스트합니다.

모든 VM이 클라우드에 마이그레이션되어 있는 특정 애플리케이션을 네트워크로 전환하려고 한다고 가정하겠습니다. 예를 들어 다음과 같습니다.
- 사설 네트워크 측에서 vyatta를 사용하여 MPLS 클라우드에 라우트를 삽입하고 {{site.data.keyword.cloud_notm}} IP 공간을 방지할 수 있도록 MPLS의 에지 라우팅 디바이스로 터널링합니다.
- {{site.data.keyword.cloud_notm}} VRF로 설정된 계정이 있습니다.
- 일부 애플리케이션은 네트워크 로드 밸런싱 가상 IP(vIP) 뒤에 있습니다. 해당 vIP는 vyatta 뒤의 가상 F5에 있는 소유 서브넷에 있습니다.

HCX를 통해 {{site.data.keyword.cloud_notm}}로 전환된 네트워크를 위해 MPLS에 더 구체적인 라우팅을 추가하면 다른 네트워크에서는 더 잘 작동하는 반면 개별 vIP에는 작동하지 않습니다. /32 라우트가 추가 중이기 때문입니다.

솔루션: WAN 제공자가 추가하는 /32 라우트를 필터링하여 제외하는 것이 일반적입니다. WAN 공급업체와 작업하여 허용하십시오.

고려사항 및 그 영향은 다음과 같습니다.
- 서브넷, vLAN 및 VXLAN을 공유하는 애플리케이션은 함께 이동해야 합니다.
- 내부 라우트 가능 IP를 사용하는 로드 밸런서 뒤에 있는 애플리케이션의 경우 함께 이동할 수 없거나 함께 이동하는 것이 바람직하지 않은 경우 라우팅을 변경해야 할 수도 있습니다. 예를 들어 한 번에 너무 많은 애플리케이션을 전환하므로 위험이 너무 많이 인지되는 경우가 해당됩니다.
- VMware 관리자, 네트워크 관리자(고객 및 WAN 공급업체 포함) 및 애플리케이션 소유자는 특정 시스템 또는 네트워크 장비에 미치는 계획된 영향이 없더라도 관련되어야 합니다.

## 관련 링크
{: #hcxclient-migrations-related}

* [HCX 컴포넌트 용어집](/docs/services/vmwaresolutions/services?topic=vmware-solutions-hcxclient-components)
* [설치 환경 준비](/docs/services/vmwaresolutions/services?topic=vmware-solutions-hcxclient-planning-prep-install)
* [HCX 클라이언트 배치](/docs/services/vmwaresolutions/services?topic=vmware-solutions-hcxclient-vcs-client-deployment)
* [HCX 온프레미스 서비스 메시](/docs/services/vmwaresolutions/services?topic=vmware-solutions-hcxclient-vcs-mesh-deployment)
* [매개변수 및 컴포넌트 모니터링](/docs/services/vmwaresolutions/services?topic=vmware-solutions-hcxclient-monitoring)
* [HCX 문제점 해결](/docs/services/vmwaresolutions/services?topic=vmware-solutions-hcxclient-troubleshooting)
